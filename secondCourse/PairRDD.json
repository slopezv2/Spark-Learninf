{"paragraphs":[{"text":"%pyspark\nprdd = sc.parallelize([('a',1), ('b',2), ('c',3)])\nprint(prdd.collect())\n\n#Usando zip\nprdd2 = sc.parallelize(zip(['a','b','c'], range(3)))\nprint(prdd2.collect())","user":"anonymous","dateUpdated":"2019-03-19T23:09:53+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('a', 1), ('b', 2), ('c', 3)]\n[('a', 0), ('b', 1), ('c', 2)]\n"}]},"apps":[],"jobName":"paragraph_1553036764062_-1807488883","id":"20190319-230604_238162441","dateCreated":"2019-03-19T23:06:04+0000","dateStarted":"2019-03-19T23:09:53+0000","dateFinished":"2019-03-19T23:10:45+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:271"},{"text":"%spark\nval prdd = sc.parallelize(List((\"a\",2),(\"b\",5),(\"c\",3)))\nprdd.collect()\n\nval prdd2 = sc.parallelize(List(\"a\", \"b\", \"c\") zip (1 to 3).toList)\nprdd2.collect()","user":"anonymous","dateUpdated":"2019-03-19T23:13:04+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"prdd: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[3] at parallelize at <console>:29\nres1: Array[(String, Int)] = Array((a,2), (b,5), (c,3))\nprdd2: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[4] at parallelize at <console>:29\nres2: Array[(String, Int)] = Array((a,1), (b,2), (c,3))\n"}]},"apps":[],"jobName":"paragraph_1553036993097_922090025","id":"20190319-230953_339699743","dateCreated":"2019-03-19T23:09:53+0000","dateStarted":"2019-03-19T23:13:04+0000","dateFinished":"2019-03-19T23:13:07+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:272"},{"text":"%pyspark\n#Ejemplo cargando desde un texto\nlinesRdd = sc.textFile(\"../datos/quijote.txt\", use_unicode= False)\nprdd = linesRdd.map(lambda x: (x.split(\" \")[0], x))\nprint(prdd.takeSample(False,2))","user":"anonymous","dateUpdated":"2019-03-19T23:21:30+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('', ''), ('compa\\xc3\\xb1\\xc3\\xada,', 'compa\\xc3\\xb1\\xc3\\xada, con s\\xc3\\xb3lo intentarla.')]\n"}]},"apps":[],"jobName":"paragraph_1553037146152_-588451126","id":"20190319-231226_726277626","dateCreated":"2019-03-19T23:12:26+0000","dateStarted":"2019-03-19T23:21:30+0000","dateFinished":"2019-03-19T23:21:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:273"},{"text":"%pyspark\n#keyBy() crea tuplas de los elementos del RDD usando la función para obtener la clave\nnrdd = sc.parallelize(xrange(2,5))\nprdd = nrdd.keyBy(lambda x: x*x)\n\nprint(prdd.collect())","user":"anonymous","dateUpdated":"2019-03-19T23:26:56+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[(4, 2), (9, 3), (16, 4)]\n"}]},"apps":[],"jobName":"paragraph_1553037615771_481027102","id":"20190319-232015_1321569382","dateCreated":"2019-03-19T23:20:15+0000","dateStarted":"2019-03-19T23:26:56+0000","dateFinished":"2019-03-19T23:26:57+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:274"},{"text":"%pyspark\n#zipWithIndex() Sirver para crear un pairRdd \nrdd = sc.parallelize([\"a\", \"b\",\"c\", \"d\",\"e\",\"f\"], 3)\nprdd = rdd.zipWithIndex()\nprint(prdd.collect())","user":"anonymous","dateUpdated":"2019-03-19T23:33:48+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('a', 0), ('b', 1), ('c', 2), ('d', 3), ('e', 4), ('f', 5)]\n"}]},"apps":[],"jobName":"paragraph_1553037963408_1912584170","id":"20190319-232603_1988855416","dateCreated":"2019-03-19T23:26:03+0000","dateStarted":"2019-03-19T23:33:49+0000","dateFinished":"2019-03-19T23:33:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:275"},{"text":"%pyspark\n#Zip con id unico\nrdd = sc.parallelize([\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"],3)\nprdd = rdd.zipWithUniqueId()\nprint(prdd.glom().collect())","user":"anonymous","dateUpdated":"2019-03-19T23:37:34+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[[('a', 0), ('b', 3)], [('c', 1), ('d', 4)], [('e', 2), ('f', 5)]]\n"}]},"apps":[],"jobName":"paragraph_1553038370728_-932099245","id":"20190319-233250_2052652496","dateCreated":"2019-03-19T23:32:50+0000","dateStarted":"2019-03-19T23:37:34+0000","dateFinished":"2019-03-19T23:37:34+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:276"},{"text":"%md\n## Transformaciones Pair RDD:","user":"anonymous","dateUpdated":"2019-03-20T16:17:11+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Transformaciones Pair RDD:</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1553038628167_1280756433","id":"20190319-233708_876524725","dateCreated":"2019-03-19T23:37:08+0000","dateStarted":"2019-03-20T16:17:11+0000","dateFinished":"2019-03-20T16:17:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:277"},{"text":"%pyspark\nfrom operator import add\nprdd = sc.parallelize([('a',2),('a',5),('b',3),('b',5),('c',2)])\nrerdd= prdd.reduceByKey(add)\nprint(rerdd.collect())","user":"anonymous","dateUpdated":"2019-03-21T23:07:27+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('a', 7), ('c', 2), ('b', 8)]\n"}]},"apps":[],"jobName":"paragraph_1553098637113_-123252774","id":"20190320-161717_1132796116","dateCreated":"2019-03-20T16:17:17+0000","dateStarted":"2019-03-21T23:07:28+0000","dateFinished":"2019-03-21T23:07:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:278"},{"text":"%pyspark\nprdd = sc.parallelize([('a',2),('a',5),('b',3),('b',5),('c',2)])\ngerdd= prdd.groupByKey()\nprint(gerdd.collect())","user":"anonymous","dateUpdated":"2019-03-21T23:09:38+0000","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":90,"optionOpen":false}}},"editorSetting":{"language":"python","editOnDblClick":true},"editorMode":"ace/mode/python","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('a', <pyspark.resultiterable.ResultIterable object at 0x7f8e97638750>), ('c', <pyspark.resultiterable.ResultIterable object at 0x7f8e976387d0>), ('b', <pyspark.resultiterable.ResultIterable object at 0x7f8e97638c90>)]\n"}]},"apps":[],"jobName":"paragraph_1553098630938_1821283492","id":"20190320-161710_808632027","dateCreated":"2019-03-20T16:17:10+0000","dateStarted":"2019-03-21T23:09:38+0000","dateFinished":"2019-03-21T23:09:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:279"},{"text":"%pyspark\nsumCount = prdd.combineByKey((lambda x: (x + 1)),(lambda x, y: (x[0] + y, x[1]+1)), (lambda x, y: (x[0] + y[0], x[1] + y[1])))\nprint(sumCount.collect())\nm = sumCount.mapValue(lambda v: float(v[0]/v[1]))\nprint(m.collect())","user":"anonymous","dateUpdated":"2019-03-21T23:09:43+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-5880566473695994500.py\", line 349, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-5880566473695994500.py\", line 337, in <module>\n    exec(code)\n  File \"<stdin>\", line 2, in <module>\n  File \"/home/vagrant/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py\", line 771, in collect\n    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())\n  File \"/home/vagrant/zeppelin/interpreter/spark/pyspark/py4j-0.9-src.zip/py4j/java_gateway.py\", line 813, in __call__\n    answer, self.gateway_client, self.target_id, self.name)\n  File \"/home/vagrant/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/sql/utils.py\", line 45, in deco\n    return f(*a, **kw)\n  File \"/home/vagrant/zeppelin/interpreter/spark/pyspark/py4j-0.9-src.zip/py4j/protocol.py\", line 308, in get_return_value\n    format(target_id, \".\", name), value)\nPy4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 7.0 failed 1 times, most recent failure: Lost task 0.0 in stage 7.0 (TID 28, localhost): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/vagrant/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/home/vagrant/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/home/vagrant/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py\", line 317, in func\n  File \"/home/vagrant/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py\", line 1784, in _mergeCombiners\n  File \"/home/vagrant/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/shuffle.py\", line 272, in mergeCombiners\n    d[k] = comb(d[k], v) if k in d else v\n  File \"<stdin>\", line 1, in <lambda>\nTypeError: 'int' object has no attribute '__getitem__'\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1845)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1858)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1929)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:927)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:926)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:405)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/home/vagrant/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/home/vagrant/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/home/vagrant/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py\", line 317, in func\n  File \"/home/vagrant/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py\", line 1784, in _mergeCombiners\n  File \"/home/vagrant/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/shuffle.py\", line 272, in mergeCombiners\n    d[k] = comb(d[k], v) if k in d else v\n  File \"<stdin>\", line 1, in <lambda>\nTypeError: 'int' object has no attribute '__getitem__'\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\t... 1 more\n\n\n"}]},"apps":[],"jobName":"paragraph_1553099641427_-1367645088","id":"20190320-163401_268541233","dateCreated":"2019-03-20T16:34:01+0000","dateStarted":"2019-03-21T23:09:44+0000","dateFinished":"2019-03-21T23:09:44+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:280"},{"text":"%pyspark\nprdd = sc.parallelize([('a',2),('a',5),('b',3),('b',5),('c',2)])\nprint(\"Claves: {}\".format(prdd.keys().collect()))\nprint(\"Valores {}\".format(prdd.values().collect()))\nprint(\"Ordenado por llave {}\".format(prdd.sortByKey().collect()))","user":"anonymous","dateUpdated":"2019-03-21T23:17:01+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Claves: ['a', 'a', 'b', 'b', 'c']\nValores [2, 5, 3, 5, 2]\nOrdenado por llave [('a', 2), ('a', 5), ('b', 3), ('b', 5), ('c', 2)]\n"}]},"apps":[],"jobName":"paragraph_1553209031330_-324063802","id":"20190321-225711_343426933","dateCreated":"2019-03-21T22:57:11+0000","dateStarted":"2019-03-21T23:17:01+0000","dateFinished":"2019-03-21T23:17:02+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:281"},{"text":"%md \n## Ejemplos de operaciones entre  dos pair RDD","user":"anonymous","dateUpdated":"2019-03-21T23:34:28+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Ejemplos de operaciones entre dos pair RDD</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1553209982413_557965091","id":"20190321-231302_695678998","dateCreated":"2019-03-21T23:13:02+0000","dateStarted":"2019-03-21T23:34:28+0000","dateFinished":"2019-03-21T23:34:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:282"},{"text":"%pyspark\nrdd1 = sc.parallelize([(\"a\",2), (\"b\",5), (\"a\", 8)]).cache()\nrdd2 = sc.parallelize([(\"c\", 7), (\"a\",1)]).cache()\nrdd3 = rdd1.join(rdd2)\nprint(rdd3.collect())","user":"anonymous","dateUpdated":"2019-03-21T23:37:27+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('a', (2, 1)), ('a', (8, 1))]\n"}]},"apps":[],"jobName":"paragraph_1553211268451_-996384884","id":"20190321-233428_1508683359","dateCreated":"2019-03-21T23:34:28+0000","dateStarted":"2019-03-21T23:37:27+0000","dateFinished":"2019-03-21T23:37:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:283"},{"text":"%pyspark\nrdd3 = rdd1.leftOuterJoin(rdd2)\nprint(rdd3.collect())","user":"anonymous","dateUpdated":"2019-03-21T23:41:12+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('a', (2, 1)), ('a', (8, 1)), ('b', (5, None))]\n"}]},"apps":[],"jobName":"paragraph_1553211409642_-2091582757","id":"20190321-233649_1370767917","dateCreated":"2019-03-21T23:36:49+0000","dateStarted":"2019-03-21T23:41:12+0000","dateFinished":"2019-03-21T23:41:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:284"},{"text":"%pyspark\nrdd3 = rdd1.rightOuterJoin(rdd2)\nprint(rdd3.collect())","user":"anonymous","dateUpdated":"2019-03-21T23:42:36+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('a', (2, 1)), ('a', (8, 1)), ('c', (None, 7))]\n"}]},"apps":[],"jobName":"paragraph_1553211672460_641074666","id":"20190321-234112_1552149057","dateCreated":"2019-03-21T23:41:12+0000","dateStarted":"2019-03-21T23:42:36+0000","dateFinished":"2019-03-21T23:42:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:285"},{"text":"%pyspark\nrdd3 = rdd1.fullOuterJoin(rdd2)\nprint(rdd3.collect())","user":"anonymous","dateUpdated":"2019-03-21T23:43:30+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('a', (2, 1)), ('a', (8, 1)), ('c', (None, 7)), ('b', (5, None))]\n"}]},"apps":[],"jobName":"paragraph_1553211743679_-1653675044","id":"20190321-234223_1048146620","dateCreated":"2019-03-21T23:42:23+0000","dateStarted":"2019-03-21T23:43:30+0000","dateFinished":"2019-03-21T23:43:30+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:286"},{"text":"%pyspark\n#Ejemplo substracción (conjuntos)\nrdd3 = rdd1.subtractByKey(rdd2)\nprint(rdd3.collect())","user":"anonymous","dateUpdated":"2019-03-21T23:47:47+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('b', 5)]\n"}]},"apps":[],"jobName":"paragraph_1553211810088_1205332736","id":"20190321-234330_1916929740","dateCreated":"2019-03-21T23:43:30+0000","dateStarted":"2019-03-21T23:47:47+0000","dateFinished":"2019-03-21T23:47:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:287"},{"text":"%pyspark\nrdd3 = rdd1.cogroup(rdd2)\nprint(rdd3.collect())\nmap = rdd3.mapValues(lambda v:[list(l) for l in v]).collectAsMap()\nprint(map)","user":"anonymous","dateUpdated":"2019-03-22T00:01:31+0000","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":89.3576,"optionOpen":false}}},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('a', (<pyspark.resultiterable.ResultIterable object at 0x7f8e9739eb50>, <pyspark.resultiterable.ResultIterable object at 0x7f8e9739e850>)), ('c', (<pyspark.resultiterable.ResultIterable object at 0x7f8e972e6750>, <pyspark.resultiterable.ResultIterable object at 0x7f8e972e67d0>)), ('b', (<pyspark.resultiterable.ResultIterable object at 0x7f8e972e6810>, <pyspark.resultiterable.ResultIterable object at 0x7f8e972e6890>))]\n{'a': [[2, 8], [1]], 'c': [[], [7]], 'b': [[5], []]}\n"}]},"apps":[],"jobName":"paragraph_1553212002215_-1210076531","id":"20190321-234642_1397621040","dateCreated":"2019-03-21T23:46:42+0000","dateStarted":"2019-03-22T00:01:32+0000","dateFinished":"2019-03-22T00:01:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:288"},{"text":"%pyspark\n","user":"anonymous","dateUpdated":"2019-03-21T23:55:52+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1553212552360_-1046961610","id":"20190321-235552_212576993","dateCreated":"2019-03-21T23:55:52+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:289"}],"name":"PairRDD","id":"2E8SBX3DK","angularObjects":{"2CCY33GTB:shared_process":[],"2CCQCYKJM:shared_process":[],"2CD8VB8N5:shared_process":[],"2CEZ3N4ZK:shared_process":[],"2CCN184W1:shared_process":[],"2CCTDCCB9:shared_process":[],"2CBRCMJB7:shared_process":[],"2CDTHYD1N:shared_process":[],"2CD85MNWZ:shared_process":[],"2CEM88R8V:shared_process":[],"2CBSSQJJR:shared_process":[],"2CBG9JDC9:shared_process":[],"2CBJUH5Z5:shared_process":[],"2CET3TKHW:shared_process":[],"2CF1VUR2D:shared_process":[],"2CCZDD8PX:shared_process":[],"2CESEPECG:shared_process":[],"2CCZGPF6E:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}